{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake = pd.read_csv('News _dataset/Fake.csv', encoding='utf-8')\n",
    "# true = pd.read_csv('News _dataset/True.csv' , encoding='utf-8')\n",
    "\n",
    "# fake['label'] = 0\n",
    "# true['label'] = 1\n",
    "\n",
    "# fake.head()\n",
    "# data = pd.concat([fake,true], ignore_index=True)\n",
    "# data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAZA/CAIRO (Reuters) - Palestinian factions, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HARARE (Reuters) - Zimbabwean police arrested ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ronna Romney McDaniel is the Chairman of the M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WASHINGTON (Reuters) - A small group of Republ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>THE HUNTINGTON BEACH, CA RALLY WAS PRETTY BIG ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44893</th>\n",
       "      <td>44893</td>\n",
       "      <td>There are two small problems with your analogy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>44894</td>\n",
       "      <td>Consortium News Exclusive: The U.S. mainstream...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>44895</td>\n",
       "      <td>Just as drug addicts and alcoholics tend to be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>44896</td>\n",
       "      <td>WASHINGTON (Reuters) - Republican presidential...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>44897</td>\n",
       "      <td>Kevin O Leary, a rich Canadian television pers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44898 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  label\n",
       "0               0  GAZA/CAIRO (Reuters) - Palestinian factions, i...      1\n",
       "1               1  HARARE (Reuters) - Zimbabwean police arrested ...      1\n",
       "2               2  Ronna Romney McDaniel is the Chairman of the M...      0\n",
       "3               3  WASHINGTON (Reuters) - A small group of Republ...      1\n",
       "4               4  THE HUNTINGTON BEACH, CA RALLY WAS PRETTY BIG ...      0\n",
       "...           ...                                                ...    ...\n",
       "44893       44893  There are two small problems with your analogy...      0\n",
       "44894       44894  Consortium News Exclusive: The U.S. mainstream...      0\n",
       "44895       44895  Just as drug addicts and alcoholics tend to be...      0\n",
       "44896       44896  WASHINGTON (Reuters) - Republican presidential...      1\n",
       "44897       44897  Kevin O Leary, a rich Canadian television pers...      0\n",
       "\n",
       "[44898 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.drop(['title', 'subject', 'date'], axis='columns', inplace=True)\n",
    "# data = data.sample(frac = 1).reset_index(drop=True)\n",
    "# print(data.tail())\n",
    "# print(data.head())\n",
    "# data.to_csv('data.csv')\n",
    "\n",
    "data = pd.read_csv('data.csv',encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(data))\n",
    "train_samples = data['text'][:-num_validation_samples]\n",
    "val_samples = data['text'][-num_validation_samples:]\n",
    "train_labels = data['label'][:-num_validation_samples]\n",
    "val_labels = data['label'][-num_validation_samples:]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Length_of_input_sentenses=500\n",
    "# matrix of pretrained weights\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=50000, output_sequence_length=500)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples)\n",
    "vectorizer.adapt(text_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize get_vocabulary method\n",
    "def _get_vocabulary():\n",
    "    keys, values = vectorizer._index_lookup_layer._table_handler.data()\n",
    "    return [x.decode('utf-8', errors='ignore') for _, x in sorted(zip(values, keys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'the', 'to', 'of', 'a']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer.get_vocabulary()\n",
    "_get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,  8988,  3266,     9,     2, 17253], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# voc = vectorizer.get_vocabulary()\n",
    "voc = _get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        \n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        \n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        \n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "#                             output_dim=100,\n",
    "#                             input_length=Length_of_input_sequences,\n",
    "#                             embeddings_initializer=matrix_of_pretrained_weights\n",
    "#                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 38238 words (11761 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
